# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #5 выполнил:
- Патракова Семена Сергеевича
- НМТ233001
- Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы
Установить необходимое программное обеспечение, которое пригодится для создания интеллектуальных моделей на Python. Рассмотреть процесс установки игрового движка Unity для разработки игр.

## Задание 1
### Найдите внутри C# скрипта “коэффициент корреляции ” и сделать выводы о том, как он влияет на обучение модели. 
Если пытаться найти клоэфициенты корреляции, то здесь можно найти сильное корреллирование между действиями агентов с получаемыми вознаграждениями (например, движение в сторону цели приводит к положительному вознаграждению), агент быстрее находит эффективные стратегии. Также корреляция прослеживается между векторной скоростью агента и его положением в пространстве, относительно цели, т.е. при слишком высоких значениях скорости агент начал бы "улетать" и точность начала бы падать.


## Задание 2
### Изменить параметры файла yaml-агента и определить какие параметры и как влияют на обучение модели. Привести описание не менее трех параметров.

batch_size: Больший batch_size может ускорить обучение и улучшить стабильность градиентов, но требует больше памяти.

learning_rate: Более высокий темп обучения ускоряет обучение, но может привести к нестабильности, грубо говоря, он просто может перескочить точку достаточного обучения и начать переобучаться. Более низкий же обеспечивает стабильность, но, соответственно, замедляет обучение.

max_steps: Определяет длительность обучения. Слишком маленькое значение может привести к недообучению, слишком большое — переобучению.

learningrateschedule: Линейное снижение learning_rat'а помогает начать обучение быстро и постепенно замедлять чтобы не упустить "пик" стабильности.

## Задание 3
### Приведите примеры, для каких игровых задачи и ситуаций могут использоваться примеры 1 и 2 с ML-Agent’ом. В каких случаях проще использовать ML-агент, а не писать программную реализацию решения?
В данном примере рассматриваются алгоритмы поиска маршрутов, а на сегодняшний день есть множество более эффективных и простых алгориртмов, выполняющих ту же задачу, т.е. теж NavMesh. Всё же, разработать полноценную нейронку для подобного - дорого и нестабильно. Про ресурсоёмкость, в общем, стоило бы промолчать, думаю, что ещё рано полноценно применять это в играх. Возможно можно взять данную нейронку более обширно и применять её для навигации непесей в целом, например в каких-либо стратегиях.





## Выводы
Данная лабораторная работа заняла куда больше времени, чем ожидалось, т.к. очень долго разбирался с библиотеками, было много конфликтов. Занялся 'высокоуровневым' обучением нейронки, поняв, как устроены гиперпараметры

Графики:
![image](https://github.com/user-attachments/assets/998195b2-5b5f-4337-977f-8fb94851db6d)



## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
